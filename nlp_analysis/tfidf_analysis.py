import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import defaultdict
import json


class RegionalTFIDF:
    """Analyse TF-IDF par r√©gion"""
    
    def __init__(self, max_features: int = 50):
        """
        Args:
            max_features: Nombre de termes √† extraire par r√©gion
        """
        self.max_features = max_features
        self.vectorizers = {}
        self.regional_terms = {}
    
    def analyze_by_region(self, df: pd.DataFrame, text_column: str = 'skills'):
        """
        Analyse TF-IDF par r√©gion.
        
        Args:
            df: DataFrame avec colonnes 'region' et text_column
            text_column: Nom de la colonne contenant le texte
        """
        print("üó∫Ô∏è  Analyse TF-IDF par r√©gion...")
        print(f"   Colonne analys√©e: {text_column}")
        print()
        
        regions = df['region'].dropna().unique()
        print(f"   R√©gions d√©tect√©es: {len(regions)}")
        
        for region in regions:
            # Filtrer les offres de cette r√©gion
            region_df = df[df['region'] == region]
            
            if len(region_df) < 5:
                continue
            
            # Combiner tous les textes de la r√©gion
            region_texts = region_df[text_column].dropna().tolist()
            
            if not region_texts:
                continue
            
            # TF-IDF pour cette r√©gion
            vectorizer = TfidfVectorizer(
                max_features=self.max_features,
                min_df=2,
                token_pattern=r'\b\w+\b'
            )
            
            try:
                tfidf_matrix = vectorizer.fit_transform(region_texts)
                
                # Moyenne TF-IDF par terme
                mean_tfidf = tfidf_matrix.mean(axis=0).A1
                feature_names = vectorizer.get_feature_names_out()
                
                # Trier par score TF-IDF
                top_indices = mean_tfidf.argsort()[-20:][::-1]
                top_terms = [(feature_names[i], mean_tfidf[i]) for i in top_indices]
                
                self.regional_terms[region] = top_terms
                self.vectorizers[region] = vectorizer
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur pour {region}: {e}")
                continue
        
        print(f"   ‚úÖ {len(self.regional_terms)} r√©gions analys√©es")
    
    def print_regional_terms(self, n_terms: int = 15):
        """Affiche les termes caract√©ristiques par r√©gion"""
        print("\n" + "=" * 80)
        print("üó∫Ô∏è  TERMES CARACT√âRISTIQUES PAR R√âGION")
        print("=" * 80)
        
        # Trier r√©gions par nombre d'offres (implicite dans l'ordre)
        for region, terms in self.regional_terms.items():
            print(f"\nüìç {region}")
            
            terms_display = []
            for term, score in terms[:n_terms]:
                terms_display.append(f"{term} ({score:.3f})")
            
            print(f"   {', '.join([t.split(' ')[0] for t, _ in terms[:n_terms]])}")
    
    def compare_regions(self, region1: str, region2: str, n_terms: int = 10):
        """
        Compare les termes caract√©ristiques de 2 r√©gions.
        
        Args:
            region1: Premi√®re r√©gion
            region2: Deuxi√®me r√©gion
            n_terms: Nombre de termes √† comparer
        """
        if region1 not in self.regional_terms or region2 not in self.regional_terms:
            print("‚ö†Ô∏è  Une des r√©gions n'a pas √©t√© analys√©e")
            return
        
        terms1 = set([t for t, _ in self.regional_terms[region1][:n_terms]])
        terms2 = set([t for t, _ in self.regional_terms[region2][:n_terms]])
        
        print(f"\nüîç Comparaison : {region1} vs {region2}")
        print("=" * 80)
        
        # Termes uniques √† r√©gion 1
        unique1 = terms1 - terms2
        if unique1:
            print(f"\n‚úÖ Sp√©cifique √† {region1}:")
            print(f"   {', '.join(list(unique1)[:10])}")
        
        # Termes uniques √† r√©gion 2
        unique2 = terms2 - terms1
        if unique2:
            print(f"\n‚úÖ Sp√©cifique √† {region2}:")
            print(f"   {', '.join(list(unique2)[:10])}")
        
        # Termes communs
        common = terms1 & terms2
        if common:
            print(f"\nü§ù Termes communs:")
            print(f"   {', '.join(list(common)[:10])}")
    
    def get_regional_specializations(self):
        """
        Identifie les sp√©cialisations par r√©gion.
        
        Returns:
            Dict {region: specialization_keywords}
        """
        specializations = {}
        
        # Mots-cl√©s indicateurs de sp√©cialisation
        tech_keywords = {
            'cloud': ['aws', 'azure', 'gcp', 'cloud', 'kubernetes', 'docker'],
            'ml_ai': ['machine', 'learning', 'deep', 'tensorflow', 'pytorch', 'nlp'],
            'big_data': ['spark', 'hadoop', 'kafka', 'big', 'data', 'streaming'],
            'bi': ['power', 'bi', 'tableau', 'looker', 'dashboard', 'reporting'],
            'web': ['react', 'javascript', 'node', 'django', 'flask', 'api'],
            'data_eng': ['airflow', 'etl', 'pipeline', 'warehouse', 'dbt']
        }
        
        for region, terms in self.regional_terms.items():
            region_terms_lower = [t.lower() for t, _ in terms[:20]]
            
            scores = defaultdict(int)
            for category, keywords in tech_keywords.items():
                for keyword in keywords:
                    if any(keyword in term for term in region_terms_lower):
                        scores[category] += 1
            
            # Top sp√©cialisation
            if scores:
                top_spec = max(scores.items(), key=lambda x: x[1])
                specializations[region] = top_spec[0]
            else:
                specializations[region] = 'g√©n√©raliste'
        
        return specializations
    
    def export_results(self, filepath: str):
        """Exporte les r√©sultats en JSON"""
        results = {}
        
        for region, terms in self.regional_terms.items():
            results[region] = {
                'top_terms': [
                    {'term': term, 'tfidf_score': float(score)}
                    for term, score in terms
                ]
            }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ R√©sultats export√©s: {filepath}")


if __name__ == "__main__":
    import sqlite3
    
    print("=" * 80)
    print("üó∫Ô∏è  ANALYSE TF-IDF PAR R√âGION")
    print("=" * 80)
    print()
    
    # Charger donn√©es
    print("üìÇ Chargement des donn√©es...")
    conn = sqlite3.connect('../database/jobs.db')
    
    query = """
        SELECT 
            fo.offer_key,
            fo.title,
            GROUP_CONCAT(ds.skill_name) as skills,
            dr.region_name as region
        FROM fact_offers fo
        LEFT JOIN fact_offer_skill fos ON fo.offer_key = fos.offer_key
        LEFT JOIN dim_skill ds ON fos.skill_key = ds.skill_key
        LEFT JOIN dim_region dr ON fo.region_key = dr.region_key
        WHERE dr.region_name IS NOT NULL
        GROUP BY fo.offer_key
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    print(f"   ‚úÖ {len(df)} offres charg√©es")
    print()
    
    # Analyse TF-IDF
    analyzer = RegionalTFIDF(max_features=50)
    analyzer.analyze_by_region(df, text_column='skills')
    
    # Afficher r√©sultats
    analyzer.print_regional_terms(n_terms=15)
    
    # Sp√©cialisations
    print("\n" + "=" * 80)
    print("üéØ SP√âCIALISATIONS R√âGIONALES")
    print("=" * 80)
    
    specializations = analyzer.get_regional_specializations()
    
    spec_labels = {
        'cloud': '‚òÅÔ∏è Cloud/DevOps',
        'ml_ai': 'ü§ñ ML/IA',
        'big_data': '‚öôÔ∏è Big Data',
        'bi': 'üìä BI/Analytics',
        'web': 'üåê Web/Full Stack',
        'data_eng': 'üîß Data Engineering',
        'g√©n√©raliste': 'üìã G√©n√©raliste'
    }
    
    for region, spec in sorted(specializations.items(), key=lambda x: x[0]):
        label = spec_labels.get(spec, spec)
        print(f"   {region:30} ‚Üí {label}")
    
    # Comparaisons int√©ressantes
    print("\n" + "=" * 80)
    print("üîç COMPARAISONS R√âGIONALES")
    print("=" * 80)
    
    # √éle-de-France vs Auvergne-Rh√¥ne-Alpes
    if '√éle-de-France' in analyzer.regional_terms and 'Auvergne-Rh√¥ne-Alpes' in analyzer.regional_terms:
        analyzer.compare_regions('√éle-de-France', 'Auvergne-Rh√¥ne-Alpes', n_terms=15)
    
    # Export
    analyzer.export_results('regional_tfidf_results.json')
    
    print("\n‚úÖ Analyse TF-IDF termin√©e !")