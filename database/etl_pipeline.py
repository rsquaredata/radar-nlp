import argparse
import sqlite3
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import sys


class ETLPipeline:
    """Pipeline ETL pour chargement des donnÃ©es"""
    
    def __init__(self, db_path: str = "jobs.db"):
        self.db_path = db_path
        self.conn = None
        self.stats = {
            'offers_inserted': 0,
            'offers_duplicates': 0,
            'skills_inserted': 0,
            'associations_created': 0
        }
    
    def connect(self):
        """Connexion Ã  la base de donnÃ©es"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.execute("PRAGMA foreign_keys = ON")
        print(f"âœ… ConnectÃ© Ã  {self.db_path}")
    
    def create_schema(self, schema_file: str = "schema.sql"):
        """CrÃ©e le schÃ©ma de la base de donnÃ©es"""
        print("\nğŸ“‹ CrÃ©ation du schÃ©ma...")
        
        with open(schema_file, 'r', encoding='utf-8') as f:
            schema_sql = f.read()
        
        # ExÃ©cuter le schÃ©ma
        self.conn.executescript(schema_sql)
        self.conn.commit()
        
        print("   âœ… SchÃ©ma crÃ©Ã© avec succÃ¨s")
    
    def load_dimensions(self, df: pd.DataFrame):
        """Charge les tables de dimensions"""
        print("\nğŸ“Š Chargement des dimensions...")
        
        # 1. dim_source
        sources = df['source'].dropna().unique()
        for source in sources:
            source_type = 'api' if 'france travail' in source.lower() else 'scraping'
            self.conn.execute(
                "INSERT OR IGNORE INTO dim_source (source_name, source_type) VALUES (?, ?)",
                (source, source_type)
            )
        print(f"   âœ… {len(sources)} sources")
        
        # 2. dim_region
        regions = df[['region', 'region_lat', 'region_lon']].dropna().drop_duplicates('region')
        for _, row in regions.iterrows():
            self.conn.execute(
                "INSERT OR IGNORE INTO dim_region (region_name, latitude, longitude) VALUES (?, ?, ?)",
                (row['region'], row['region_lat'], row['region_lon'])
            )
        print(f"   âœ… {len(regions)} rÃ©gions")
        
        # 3. dim_company
        companies = df['company'].dropna().unique()
        for company in companies:
            self.conn.execute(
                "INSERT OR IGNORE INTO dim_company (company_name) VALUES (?)",
                (company,)
            )
        print(f"   âœ… {len(companies)} entreprises")
        
        # 4. dim_contract
        contracts = df['contract_type'].dropna().unique()
        for contract in contracts:
            self.conn.execute(
                "INSERT OR IGNORE INTO dim_contract (contract_type) VALUES (?)",
                (contract,)
            )
        print(f"   âœ… {len(contracts)} types de contrat")
        
        self.conn.commit()
    
    def load_skills(self, df: pd.DataFrame):
        """Charge les compÃ©tences dans dim_skill"""
        print("\nğŸ¯ Chargement des compÃ©tences...")
        
        all_skills = set()
        
        for _, row in df.iterrows():
            # CompÃ©tences techniques
            if pd.notna(row.get('competences')):
                try:
                    competences = eval(row['competences']) if isinstance(row['competences'], str) else row['competences']
                    for skill in competences:
                        all_skills.add((skill, 'competences', 'unknown'))
                except:
                    pass
            
            # Savoir-Ãªtre
            if pd.notna(row.get('savoir_etre')):
                try:
                    savoir_etre = eval(row['savoir_etre']) if isinstance(row['savoir_etre'], str) else row['savoir_etre']
                    for skill in savoir_etre:
                        all_skills.add((skill, 'savoir_etre', 'unknown'))
                except:
                    pass
        
        # InsÃ©rer
        for skill_name, skill_type, skill_category in all_skills:
            self.conn.execute(
                "INSERT OR IGNORE INTO dim_skill (skill_name, skill_type, skill_category) VALUES (?, ?, ?)",
                (skill_name, skill_type, skill_category)
            )
        
        self.conn.commit()
        self.stats['skills_inserted'] = len(all_skills)
        print(f"   âœ… {len(all_skills)} compÃ©tences uniques")
    
    def load_offers(self, df: pd.DataFrame):
        """Charge les offres dans fact_offers"""
        print("\nğŸ“ Chargement des offres...")
        
        cursor = self.conn.cursor()
        
        for idx, row in df.iterrows():
            try:
                # RÃ©cupÃ©rer les clÃ©s Ã©trangÃ¨res
                source_key = self._get_key("dim_source", "source_name", row.get('source'))
                region_key = self._get_key("dim_region", "region_name", row.get('region'))
                company_key = self._get_key("dim_company", "company_name", row.get('company'))
                contract_key = self._get_key("dim_contract", "contract_type", row.get('contract_type'))
                
                # Compter les compÃ©tences
                competences_count = 0
                savoir_etre_count = 0
                
                if pd.notna(row.get('competences')):
                    try:
                        comp = eval(row['competences']) if isinstance(row['competences'], str) else row['competences']
                        competences_count = len(comp)
                    except:
                        pass
                
                if pd.notna(row.get('savoir_etre')):
                    try:
                        se = eval(row['savoir_etre']) if isinstance(row['savoir_etre'], str) else row['savoir_etre']
                        savoir_etre_count = len(se)
                    except:
                        pass
                
                skills_count = competences_count + savoir_etre_count
                
                # InsÃ©rer l'offre (si pas de doublon grÃ¢ce Ã  UNIQUE uid)
                cursor.execute("""
                    INSERT OR IGNORE INTO fact_offers 
                    (uid, offer_id, source_key, region_key, company_key, contract_key,
                     title, source_url, location, salary, remote, published_date, description,
                     skills_count, competences_count, savoir_etre_count, added_by)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'import')
                """, (
                    row['uid'], row['offer_id'], source_key, region_key, company_key, contract_key,
                    row['title'], row.get('source_url'), row.get('location'), 
                    row.get('salary'), row.get('remote'), row.get('published_date'), 
                    row.get('description'), skills_count, competences_count, savoir_etre_count
                ))
                
                if cursor.rowcount > 0:
                    self.stats['offers_inserted'] += 1
                else:
                    self.stats['offers_duplicates'] += 1
                
            except Exception as e:
                print(f"   âš ï¸  Erreur ligne {idx}: {e}")
                continue
            
            if (idx + 1) % 100 == 0:
                print(f"   TraitÃ© {idx + 1}/{len(df)}")
        
        self.conn.commit()
        print(f"   âœ… {self.stats['offers_inserted']} offres insÃ©rÃ©es")
        print(f"   âš ï¸  {self.stats['offers_duplicates']} doublons ignorÃ©s")
    
    def load_offer_skills(self, df: pd.DataFrame):
        """Charge les associations offre â†” compÃ©tence"""
        print("\nğŸ”— CrÃ©ation des associations offre â†” compÃ©tence...")
        
        cursor = self.conn.cursor()
        
        for idx, row in df.iterrows():
            # RÃ©cupÃ©rer offer_key
            cursor.execute("SELECT offer_key FROM fact_offers WHERE uid = ?", (row['uid'],))
            result = cursor.fetchone()
            
            if not result:
                continue
            
            offer_key = result[0]
            
            # CompÃ©tences techniques
            if pd.notna(row.get('competences')):
                try:
                    competences = eval(row['competences']) if isinstance(row['competences'], str) else row['competences']
                    for skill_name in competences:
                        skill_key = self._get_key("dim_skill", "skill_name", skill_name)
                        if skill_key:
                            cursor.execute(
                                "INSERT OR IGNORE INTO fact_offer_skill (offer_key, skill_key) VALUES (?, ?)",
                                (offer_key, skill_key)
                            )
                            if cursor.rowcount > 0:
                                self.stats['associations_created'] += 1
                except:
                    pass
            
            # Savoir-Ãªtre
            if pd.notna(row.get('savoir_etre')):
                try:
                    savoir_etre = eval(row['savoir_etre']) if isinstance(row['savoir_etre'], str) else row['savoir_etre']
                    for skill_name in savoir_etre:
                        skill_key = self._get_key("dim_skill", "skill_name", skill_name)
                        if skill_key:
                            cursor.execute(
                                "INSERT OR IGNORE INTO fact_offer_skill (offer_key, skill_key) VALUES (?, ?)",
                                (offer_key, skill_key)
                            )
                            if cursor.rowcount > 0:
                                self.stats['associations_created'] += 1
                except:
                    pass
            
            if (idx + 1) % 100 == 0:
                print(f"   TraitÃ© {idx + 1}/{len(df)}")
        
        self.conn.commit()
        print(f"   âœ… {self.stats['associations_created']} associations crÃ©Ã©es")
    
    def _get_key(self, table: str, column: str, value):
        """RÃ©cupÃ¨re la clÃ© primaire d'une dimension"""
        if pd.isna(value):
            return None
        
        cursor = self.conn.cursor()
        key_column = table.replace('dim_', '') + '_key'
        cursor.execute(f"SELECT {key_column} FROM {table} WHERE {column} = ?", (value,))
        result = cursor.fetchone()
        return result[0] if result else None
    
    def print_stats(self):
        """Affiche les statistiques finales"""
        print("\n" + "=" * 80)
        print("ğŸ“Š STATISTIQUES FINALES")
        print("=" * 80)
        
        cursor = self.conn.cursor()
        
        # Stats globales
        cursor.execute("SELECT * FROM v_stats_global")
        stats = cursor.fetchone()
        
        print(f"\nâœ… Offres : {stats[0]:,}")
        print(f"âœ… RÃ©gions : {stats[1]:,}")
        print(f"âœ… CompÃ©tences totales : {stats[2]:,}")
        print(f"   â€¢ CompÃ©tences techniques : {stats[3]:,}")
        print(f"   â€¢ Savoir-Ãªtre : {stats[4]:,}")
        print(f"âœ… Moyenne compÃ©tences/offre : {stats[5]:.1f}")
        print(f"\nâœ… Associations offre â†” compÃ©tence : {self.stats['associations_created']:,}")
        
        # Top 10 compÃ©tences
        print("\nğŸ† TOP 10 COMPÃ‰TENCES :")
        cursor.execute("SELECT skill_name, offer_count, percentage FROM v_top_skills LIMIT 10")
        for skill_name, count, pct in cursor.fetchall():
            print(f"   â€¢ {skill_name:25} {count:4} offres ({pct:.1f}%)")
        
        # Top 5 rÃ©gions
        print("\nğŸ—ºï¸  TOP 5 RÃ‰GIONS :")
        cursor.execute("SELECT region_name, offer_count FROM v_offers_by_region LIMIT 5")
        for region, count in cursor.fetchall():
            print(f"   â€¢ {region:30} {count:4} offres")
    
    def close(self):
        """Ferme la connexion"""
        if self.conn:
            self.conn.close()
            print("\nâœ… Connexion fermÃ©e")


def main():
    parser = argparse.ArgumentParser(description="Pipeline ETL - Chargement des donnÃ©es")
    parser.add_argument('-i', '--input', required=True, help="Fichier CSV d'entrÃ©e")
    parser.add_argument('--db', default='jobs.db', help="Nom de la base de donnÃ©es")
    parser.add_argument('--schema', default='schema.sql', help="Fichier schema SQL")
    parser.add_argument('--recreate', action='store_true', help="RecrÃ©er la base (supprime l'existante)")
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ—„ï¸  PIPELINE ETL - CHARGEMENT BASE DE DONNÃ‰ES")
    print("=" * 80)
    print()
    print(f"ğŸ“‚ Fichier source : {args.input}")
    print(f"ğŸ—„ï¸  Base de donnÃ©es : {args.db}")
    print()
    
    # Supprimer la base si --recreate
    if args.recreate and Path(args.db).exists():
        Path(args.db).unlink()
        print("âš ï¸  Base de donnÃ©es existante supprimÃ©e")
        print()
    
    # Charger les donnÃ©es CSV
    print("ğŸ“‚ Chargement du CSV...")
    df = pd.read_csv(args.input)
    print(f"   âœ… {len(df):,} lignes chargÃ©es")
    
    # Pipeline ETL
    etl = ETLPipeline(db_path=args.db)
    
    try:
        etl.connect()
        etl.create_schema(schema_file=args.schema)
        etl.load_dimensions(df)
        etl.load_skills(df)
        etl.load_offers(df)
        etl.load_offer_skills(df)
        etl.print_stats()
        
    except Exception as e:
        print(f"\nâŒ ERREUR : {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        etl.close()
    
    print("\n" + "=" * 80)
    print("âœ… PIPELINE ETL TERMINÃ‰")
    print("=" * 80)
    print()
    print(f"ğŸ’¡ La base de donnÃ©es '{args.db}' est prÃªte Ã  Ãªtre utilisÃ©e !")
    print()


if __name__ == "__main__":
    main()